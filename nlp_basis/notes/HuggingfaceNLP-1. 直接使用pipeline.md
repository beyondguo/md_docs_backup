---
title:  HuggingfaceğŸ¤—NLPç¬”è®°1ï¼šç›´æ¥ä½¿ç”¨pipelineï¼Œæ˜¯ä¸ªäººå°±èƒ½ç©NLP
published: 2021-9-20
sidebar: auto
---

> ã€ŒHuggingfaceğŸ¤—NLPç¬”è®°ç³»åˆ—-ç¬¬1é›†ã€
> æœ€è¿‘è·Ÿç€Huggingfaceä¸Šçš„NLP tutorialèµ°äº†ä¸€éï¼ŒæƒŠå¹å±…ç„¶æœ‰å¦‚æ­¤å¥½çš„è®²è§£Transformersç³»åˆ—çš„NLPæ•™ç¨‹ï¼Œäºæ˜¯å†³å®šè®°å½•ä¸€ä¸‹å­¦ä¹ çš„è¿‡ç¨‹ï¼Œåˆ†äº«æˆ‘çš„ç¬”è®°ï¼Œå¯ä»¥ç®—æ˜¯å®˜æ–¹æ•™ç¨‹çš„ç²¾ç®€ç‰ˆã€‚ä½†æœ€æ¨èçš„ï¼Œè¿˜æ˜¯ç›´æ¥è·Ÿç€å®˜æ–¹æ•™ç¨‹æ¥ä¸€éï¼ŒçœŸæ˜¯ä¸€ç§äº«å—ã€‚

- å®˜æ–¹æ•™ç¨‹ç½‘å€ï¼šhttps://huggingface.co/course/chapter1
- æœ¬æœŸå†…å®¹å¯¹åº”ç½‘å€ï¼šhttps://huggingface.co/course/chapter1/3?fw=pt
- æœ¬ç³»åˆ—ç¬”è®°çš„GitHubï¼š https://github.com/beyondguo/Learn_PyTorch/tree/master/HuggingfaceNLP

---

# ç›´æ¥ä½¿ç”¨Pipelineå·¥å…·åšNLPä»»åŠ¡

`Pipeline`æ˜¯Huggingfaceçš„ä¸€ä¸ªåŸºæœ¬å·¥å…·ï¼Œå¯ä»¥ç†è§£ä¸ºä¸€ä¸ªç«¯åˆ°ç«¯(end-to-end)çš„ä¸€é”®è°ƒç”¨Transformeræ¨¡å‹çš„å·¥å…·ã€‚å®ƒå…·å¤‡äº†æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å¤„ç†ã€æ¨¡å‹è¾“å‡ºåå¤„ç†ç­‰æ­¥éª¤ï¼Œå¯ä»¥ç›´æ¥è¾“å…¥åŸå§‹æ•°æ®ï¼Œç„¶åç»™å‡ºé¢„æµ‹ç»“æœï¼Œååˆ†æ–¹ä¾¿ã€‚

ç»™å®šä¸€ä¸ªä»»åŠ¡ä¹‹åï¼Œpipelineä¼šè‡ªåŠ¨è°ƒç”¨ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œç„¶åæ ¹æ®ä½ ç»™çš„è¾“å…¥æ‰§è¡Œä¸‹é¢ä¸‰ä¸ªæ­¥éª¤ï¼š
1. é¢„å¤„ç†è¾“å…¥æ–‡æœ¬ï¼Œè®©å®ƒå¯è¢«æ¨¡å‹è¯»å–
2. æ¨¡å‹å¤„ç†
3. æ¨¡å‹è¾“å‡ºçš„åå¤„ç†ï¼Œè®©é¢„æµ‹ç»“æœå¯è¯»

ä¸€ä¸ªä¾‹å­å¦‚ä¸‹ï¼š


```python
from transformers import pipeline

clf = pipeline('sentiment-analysis')
clf('Haha, today is a nice day!')
```
è¾“å‡ºï¼š
```shell
[{'label': 'POSITIVE', 'score': 0.9998709559440613}]
```


è¿˜å¯ä»¥**ç›´æ¥æ¥å—å¤šä¸ªå¥å­**ï¼Œä¸€èµ·é¢„æµ‹ï¼š
```python
clf(['good','nice','bad'])
```
è¾“å‡ºï¼š
```shell
[{'label': 'POSITIVE', 'score': 0.9998160600662231},
 {'label': 'POSITIVE', 'score': 0.9998552799224854},
 {'label': 'NEGATIVE', 'score': 0.999782383441925}]
```



pipelineæ”¯æŒçš„**task**åŒ…æ‹¬ï¼š

- `"feature-extraction"`: will return a FeatureExtractionPipeline.
- `"text-classification"`: will return a TextClassificationPipeline.
- `"sentiment-analysis"`: (alias of "text-classification") will return a TextClassificationPipeline.
- `"token-classification"`: will return a TokenClassificationPipeline.
- `"ner"` (alias of "token-classification"): will return a TokenClassificationPipeline.
- `"question-answering"`: will return a QuestionAnsweringPipeline.
- `"fill-mask"`: will return a FillMaskPipeline.
- `"summarization"`: will return a SummarizationPipeline.
- `"translation_xx_to_yy"`: will return a TranslationPipeline.
- `"text2text-generation"`: will return a Text2TextGenerationPipeline.
- `"text-generation"`: will return a TextGenerationPipeline.
- `"zero-shot-classification"`: will return a ZeroShotClassificationPipeline.
- `"conversational"`: will return a ConversationalPipeline.

---

ä¸‹é¢å¯ä»¥å¯ä»¥æ¥è¯•è¯•ç”¨pipelineç›´æ¥æ¥åšä¸€äº›ä»»åŠ¡ï¼š

## Have a try: Zero-shot-classification
é›¶æ ·æœ¬å­¦ä¹ ï¼Œå°±æ˜¯è®­ç»ƒä¸€ä¸ªå¯ä»¥é¢„æµ‹ä»»ä½•æ ‡ç­¾çš„æ¨¡å‹ï¼Œè¿™äº›æ ‡ç­¾å¯ä»¥ä¸å‡ºç°åœ¨è®­ç»ƒé›†ä¸­ã€‚

ä¸€ç§é›¶æ ·æœ¬å­¦ä¹ çš„æ–¹æ³•ï¼Œå°±æ˜¯é€šè¿‡NLIï¼ˆæ–‡æœ¬è•´å«ï¼‰ä»»åŠ¡ï¼Œè®­ç»ƒä¸€ä¸ªæ¨ç†æ¨¡å‹ï¼Œæ¯”å¦‚è¿™ä¸ªä¾‹å­ï¼š
```python
premise = 'Who are you voting for in 2020?'
hypothesis = 'This text is about politics.'
```
ä¸Šé¢æœ‰ä¸€ä¸ªå‰æ(premise)å’Œä¸€ä¸ªå‡è®¾(hypothesis)ï¼ŒNLIä»»åŠ¡å°±æ˜¯å»é¢„æµ‹ï¼Œåœ¨è¿™ä¸ªpremiseä¸‹ï¼Œhypothesisæ˜¯å¦æˆç«‹ã€‚

>NLI (natural language inference)ä»»åŠ¡ï¼šit classifies if two sentences are logically linked across three labels (contradiction, neutral, entailment).

é€šè¿‡è¿™æ ·çš„è®­ç»ƒï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥æŠŠhypothesisä¸­çš„politicsæ¢æˆå…¶ä»–è¯å„¿ï¼Œå°±å¯ä»¥å®ç°zero-shot-learningäº†ã€‚è€ŒHuggingface pipelineä¸­çš„é›¶æ ·æœ¬å­¦ä¹ ï¼Œä½¿ç”¨çš„å°±æ˜¯åœ¨NLIä»»åŠ¡ä¸Šé¢„è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚


```python
clf = pipeline('zero-shot-classification')

clf(sequences=["A helicopter is flying in the sky",
               "A bird is flying in the sky"],
    candidate_labels=['animal','machine'])  # labelså¯ä»¥å®Œå…¨è‡ªå®šä¹‰
```

è¾“å‡ºï¼š
```shell
[{'sequence': 'A helicopter is flying in the sky',
  'labels': ['machine', 'animal'],
  'scores': [0.9938627481460571, 0.006137280724942684]},
 {'sequence': 'A bird is flying in the sky',
  'labels': ['animal', 'machine'],
  'scores': [0.9987970590591431, 0.0012029369827359915]}]
```

å‚è€ƒé˜…è¯»ï¼š
- å®˜æ–¹ Zero-shot-classification Pipelineæ–‡æ¡£ï¼šhttps://huggingface.co/transformers/main_classes/pipelines.html#transformers.ZeroShotClassificationPipeline
- é›¶æ ·æœ¬å­¦ä¹ ç®€ä»‹ï¼šhttps://mp.weixin.qq.com/s/6aBzR0O3pwA8-btsuDX82g


## Have a try: Text Generation
Huggingface pipelineé»˜è®¤çš„æ¨¡å‹éƒ½æ˜¯è‹±æ–‡çš„ï¼Œæ¯”å¦‚å¯¹äºtext generationé»˜è®¤ä½¿ç”¨gpt2ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥æŒ‡å®šHuggingface Hubä¸Šå…¶ä»–çš„text generationæ¨¡å‹ï¼Œè¿™é‡Œæˆ‘æ‰¾åˆ°ä¸€ä¸ªä¸­æ–‡çš„ï¼š

```python
generator = pipeline('text-generation', model='liam168/chat-DialoGPT-small-zh')  
```
ç»™ä¸€ä¸ªåˆå§‹è¯å¥å¼€å§‹ç”Ÿäº§ï¼š

```python
generator('ä¸Šåˆ')
```
è¾“å‡ºï¼š
```shell
[{'generated_text': 'ä¸Šåˆä¸Šç­å§'}]
```



## Have a try: Mask Filling


```python
unmasker = pipeline('fill-mask')

unmasker('What the <mask>?', top_k=3)  # æ³¨æ„ä¸åŒçš„æ¨¡å‹ï¼ŒMASK tokenå¯èƒ½ä¸ä¸€æ ·ï¼Œä¸ä¸€å®šéƒ½æ˜¯ <mask>
```

è¾“å‡ºï¼š


```shell
[{'sequence': 'What the heck?',
  'score': 0.3783760964870453,
  'token': 17835,
  'token_str': ' heck'},
 {'sequence': 'What the hell?',
  'score': 0.32931089401245117,
  'token': 7105,
  'token_str': ' hell'},
 {'sequence': 'What the fuck?',
  'score': 0.14645449817180634,
  'token': 26536,
  'token_str': ' fuck'}]
```



## å…¶ä»–Tasks

è¿˜æœ‰å¾ˆå¤šå…¶ä»–çš„pipelineï¼Œæ¯”å¦‚NERï¼Œæ¯”å¦‚summarizationï¼Œè¿™é‡Œå°±ä¸ä¸€ä¸€å°è¯•äº†ã€‚

æƒ³çœ‹å®˜æ–¹å®ä¾‹çš„å¯ä»¥å‚è§ï¼š https://huggingface.co/course/chapter1/3?fw=pt



---

æ€»ä¹‹ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼ŒHuggingfaceæä¾›çš„pipelineæ¥å£ï¼Œå°±æ˜¯ä¸€ä¸ªâ€æ‹¿æ¥å³ç”¨â€œçš„ç«¯åˆ°ç«¯çš„æ¥å£ï¼Œåªè¦Huggingface Hubä¸Šæœ‰å¯¹åº”çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å‡ è¡Œä»£ç å°±å¯ä»¥ç›´æ¥æ‹¿æ¥åšä»»åŠ¡äº†ï¼ŒçœŸæ˜¯é€ ç¦å¤§ä¼—å•Šï¼



ä¸‹ä¸€ç¯‡ç¬”è®°ï¼Œä¼šå›é¡¾ä¸€ä¸‹Transformeræ¨¡å‹çš„å‘å±•å’ŒåŸºæœ¬æ¶æ„ï¼Œè®©æˆ‘ä»¬å¯¹è¿™äº›å·¥å…·èƒŒåçš„æ¨¡å‹æ›´åŠ äº†è§£ã€‚

