---
title: 「杂谈」理解L1,L2正则化的正确姿势
published: 2021-6-24
sidebar: auto
---

# 理解L1,L2正则化的正确姿势

> 提到正则化，不得不提L1和L2正则化。作为两种常见的正则项，它们的特点却截然不同。简而言之，L1正则化倾向于让模型得到一个稀疏解，即参数会有很多0；而L2正则化的解相对来说会平滑许多。这是为什么呢？

先吐槽：

凡是看过对比L1和L2的博客的，一定看到这这些图：
![](https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-5-28/1622131927187-image.png)

是的，就是这些等高线图，配合一个方框♦️一个圆圈⭕️ 。大多数博客都是摆上这么一张图就希望读者能够理解，这些图看似形象地不得了，吸引我们去看，结果看半天还是一头雾水。第一个画出这种图的人，一定是高手，是神，因为他深刻掌握了L1和L2的精髓。但是，由于是神，他便离凡人远了些，这个图就是典型的“看似生动形象，实则高高在上”的图。

其实，只要对这些图，多画几笔，多讲几句话，我们就可以很容易理解了。下面我来给出我画的图，个人觉得更容易理解。

首先写出L1正则化和L2正则化的公式：
$$
L1: J_{L1} = J + \alpha\|w\|_1 = J + \frac{\alpha}{n}\sum_{i=1}^{n}|w_i|
$$
$$
L2: J_{L2} = J + \alpha{\|w\|_2}^2 = J + \frac{\alpha}{n}\sum_{i=1}^{n}{w_i}^2
$$



## 一、用等高线展示L1，L2正则化的正确姿势

![L1，L2正则化示意图](https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-5-28/1622182427508-image.png)


图中：
- 蓝色的一层层的线，代表**正则项的等高线**，对于L1，它是菱形的，对于L2，它是圆形的；
- 绿色的一层层的圆圈，代表**原始损失函数的等高线图**；
- 黑色的是坐标轴，这里展示的是二维特征的坐标轴。

**关键的关键**：
1. 蓝色的等高线和绿色的等高线，分别代表了两个优化问题。对原始的损失函数J添加了正则像之后，优化问题就变成了两个子优化问题的博弈。
2. 当J和正则项之和最小时，上述的博弈取得平衡。而此时平衡点一定是相切点/端点。相切点的具体位置，取决于正则项的惩罚力度，也就是公式里的$\alpha$。每一个平衡点，对应着一个$\alpha$的设置。
- 可以想象：**当惩罚力度大时，蓝色的线希望扯着绿色的线，往靠近坐标轴的方向移动**，而**惩罚力度小时，绿色的线希望扯着蓝色的线，往远离坐标轴的方向移动**。

那么就好理解了，我们可以发现：
- 对于L1正则化，蓝线和绿线的相切点，随着蓝线不断靠近坐标轴，早晚会碰到坐标轴，抵达坐标轴之后，最优点会保持在L1等高线的端点处，依然在坐标轴上，故某个特征的值会变为0。
- 而L2的相切点则只能无限接近坐标轴，惩罚力度再大，都到不了0。

### - 上面这个图还是复杂了点儿，能不能分解/分步一下？

当然，真正让我彻底理解的，是当我画出下面这个图的时候：

![L1正则化示意图](https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-5-28/1622183471818-image.png)

图中展示的都是达到最优的时候的两个等高线的关系。图注都写在图片里了，随着$\alpha$的增大，L1的蓝色的方框不断缩小，拉扯着J的绿色圆圈变大，第三张子图的时候，最优点到达了L1的顶点，后面如果继续增大的话，最优点会沿着纵坐标往下滑。所以，当$\alpha$超过某个阈值的时候，最优解中的w1就会总等于0.

![L2正则化示意图](https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-5-28/1622183565601-image.png)
L2理解起来久简单多了，两个圆一直都是相切的状态，切点永远到不了原点，也就没法让某个特征等于0。

这两张图，才真正展示了一般情况下的L1和L2正则化的特点，解释了为什么L1正则化会导致稀疏解。

## 二、最后辅以推导

只有从直觉上，道理上理解了L1和L2的特点，我们再去用数学推导才有意义。

要看是否会导致稀疏解，我们可以看0附近的导数是否导致0是其邻域内的极值点：

![](https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-5-28/1622185917818-image.png)


![假设J在0处的导数是一个很小的正数，那么在0的邻域内，J的导数和J的大致的样子](https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-5-28/1622186786169-image.png)


上面的推导表明，对于L1，0的邻域内，存在某种条件，使得导数先负后正，即函数先减后增，所以0是极值点。而条件是：原损失函数J在某参数为0处的导数在$(-\frac{\alpha}{n},\frac{\alpha}{n})$范围内。这个条件，说直白一点就是**有没有某特征对损失函数影响不大**。

而L2在0处的导数，就等于J在0处的导数。只有当原始优化问题的最优解本身就是稀疏解的时候，才会使得该参数为0，而这个显然不常见。

---
以上。听懂掌声！






